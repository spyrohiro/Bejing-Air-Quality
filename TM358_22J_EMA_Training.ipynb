{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c0f9afcf",
      "metadata": {
        "id": "c0f9afcf"
      },
      "source": [
        "# Bejing Air Quality Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13eba1b1",
      "metadata": {
        "id": "13eba1b1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np # linear algebra\n",
        "import random\n",
        "import json\n",
        "import joblib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import Sequential, optimizers, metrics\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1efae327",
      "metadata": {
        "id": "1efae327"
      },
      "outputs": [],
      "source": [
        "SEQUENCE_LEN = 5\n",
        "BATCH_SIZE = 128\n",
        "PM_25_BOUNDARIES = [35, 75, 150]\n",
        "NUM_CLASSES = len(PM_25_BOUNDARIES) + 1\n",
        "NUM_COLS = 16\n",
        "batch_size = BATCH_SIZE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0d83ed8",
      "metadata": {
        "id": "b0d83ed8"
      },
      "source": [
        "# PM2.5 categorisation project"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2ef3fe0",
      "metadata": {
        "id": "a2ef3fe0"
      },
      "source": [
        "This project looks at the weather recording stations data around Beijing it then uses various machine learning methods to predict PM2.5 concentrations, this notebook is the *training* notebook.\n",
        "\n",
        "it does this by classifying them into four categories:\n",
        "\n",
        "<=35\n",
        "\n",
        "36-75\n",
        "\n",
        "76-150\n",
        "\n",
        ",>151\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6601f2b",
      "metadata": {
        "id": "d6601f2b"
      },
      "source": [
        "Datasets:\n",
        "\n",
        "The normalised data was batched and windowed, then PCA batched data was created. The regular data was then extracted to numpy data there was a 70-20-10 split of training, validation and test data.\n",
        "\n",
        "Models:\n",
        "\n",
        "lstm_base: the baseline lstm model\n",
        "\n",
        "lstm_pca: a lstm model with pca\n",
        "\n",
        "lstm_deep: a deeper model with dropout layers\n",
        "\n",
        "rfp: a regular randomforest with default parameters\n",
        "\n",
        "rfh: random_forest with changed hyper-paramters\n",
        "\n",
        "lstm_final: a lstm with three performance investigations on the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5464c7f",
      "metadata": {
        "id": "e5464c7f"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "base_dir = '/datasets/beijing-air/normalised'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9bf656b",
      "metadata": {
        "id": "a9bf656b",
        "outputId": "5a4f83ea-5fbb-476c-c658-eb8ee120c27d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/datasets/beijing-air/normalised/PRSA_Data_Gucheng_20130301-20170228.csv',\n",
              " '/datasets/beijing-air/normalised/PRSA_Data_Dongsi_20130301-20170228.csv',\n",
              " '/datasets/beijing-air/normalised/PRSA_Data_Aotizhongxin_20130301-20170228.csv',\n",
              " '/datasets/beijing-air/normalised/PRSA_Data_Nongzhanguan_20130301-20170228.csv',\n",
              " '/datasets/beijing-air/normalised/PRSA_Data_Wanshouxigong_20130301-20170228.csv',\n",
              " '/datasets/beijing-air/normalised/PRSA_Data_Wanliu_20130301-20170228.csv',\n",
              " '/datasets/beijing-air/normalised/PRSA_Data_Dingling_20130301-20170228.csv',\n",
              " '/datasets/beijing-air/normalised/PRSA_Data_Changping_20130301-20170228.csv',\n",
              " '/datasets/beijing-air/normalised/PRSA_Data_Tiantan_20130301-20170228.csv',\n",
              " '/datasets/beijing-air/normalised/PRSA_Data_Shunyi_20130301-20170228.csv',\n",
              " '/datasets/beijing-air/normalised/PRSA_Data_Guanyuan_20130301-20170228.csv',\n",
              " '/datasets/beijing-air/normalised/PRSA_Data_Huairou_20130301-20170228.csv']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datafiles = glob.glob(base_dir + '/*.csv')\n",
        "datafiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b333edd5",
      "metadata": {
        "id": "b333edd5",
        "outputId": "fb9f1082-375d-4ae6-d5f4-9ae02dbf0f82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['/datasets/beijing-air/normalised/PRSA_Data_Gucheng_20130301-20170228.csv',\n",
              "  '/datasets/beijing-air/normalised/PRSA_Data_Dongsi_20130301-20170228.csv',\n",
              "  '/datasets/beijing-air/normalised/PRSA_Data_Aotizhongxin_20130301-20170228.csv',\n",
              "  '/datasets/beijing-air/normalised/PRSA_Data_Nongzhanguan_20130301-20170228.csv',\n",
              "  '/datasets/beijing-air/normalised/PRSA_Data_Wanshouxigong_20130301-20170228.csv',\n",
              "  '/datasets/beijing-air/normalised/PRSA_Data_Wanliu_20130301-20170228.csv',\n",
              "  '/datasets/beijing-air/normalised/PRSA_Data_Dingling_20130301-20170228.csv'],\n",
              " ['/datasets/beijing-air/normalised/PRSA_Data_Changping_20130301-20170228.csv',\n",
              "  '/datasets/beijing-air/normalised/PRSA_Data_Tiantan_20130301-20170228.csv'],\n",
              " ['/datasets/beijing-air/normalised/PRSA_Data_Shunyi_20130301-20170228.csv',\n",
              "  '/datasets/beijing-air/normalised/PRSA_Data_Guanyuan_20130301-20170228.csv',\n",
              "  '/datasets/beijing-air/normalised/PRSA_Data_Huairou_20130301-20170228.csv'])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_datafiles = datafiles[:7]\n",
        "validation_datafiles = datafiles[7:9]\n",
        "test_datafiles = datafiles[9:]\n",
        "train_datafiles, validation_datafiles, test_datafiles"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f43e6cf",
      "metadata": {
        "id": "6f43e6cf"
      },
      "source": [
        "# load and chain *no* pca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0638e39",
      "metadata": {
        "id": "c0638e39"
      },
      "outputs": [],
      "source": [
        "def load_and_chain_ds(filenames):\n",
        "    base_ds = tf.data.experimental.make_csv_dataset(\n",
        "        filenames[0],\n",
        "        batch_size=BATCH_SIZE,\n",
        "        label_name='PM2.5',\n",
        "        shuffle=False, num_epochs=1,\n",
        "        )\n",
        "    for f in filenames[1:]:\n",
        "        d = tf.data.experimental.make_csv_dataset(\n",
        "            f,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            label_name='PM2.5',\n",
        "            shuffle=False, num_epochs=1,\n",
        "            )\n",
        "        base_ds = base_ds.concatenate(d)\n",
        "    base_ds = base_ds.cache()\n",
        "    base_ds = base_ds.prefetch(tf.data.AUTOTUNE)\n",
        "    return base_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8df5e975",
      "metadata": {
        "id": "8df5e975"
      },
      "outputs": [],
      "source": [
        "train_ds = load_and_chain_ds(train_datafiles)\n",
        "validation_ds = load_and_chain_ds(validation_datafiles)\n",
        "test_ds = load_and_chain_ds(test_datafiles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5db4075",
      "metadata": {
        "id": "c5db4075",
        "outputId": "e84a32a3-aa6a-4a2c-e320-a6b6ebbc475c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(OrderedDict([('PM10', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('SO2', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('NO2', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('CO', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('O3', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('TEMP', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('PRES', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('DEWP', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('RAIN', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('station', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('day_sin', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('day_cos', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('year_sin', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('year_cos', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('wind_x', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('wind_y', TensorSpec(shape=(None,), dtype=tf.float32, name=None))]), TensorSpec(shape=(None,), dtype=tf.float32, name=None))>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f09b370",
      "metadata": {
        "id": "9f09b370"
      },
      "source": [
        "# massage input no pca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3a73a11",
      "metadata": {
        "id": "b3a73a11"
      },
      "outputs": [],
      "source": [
        "pm25_categories = Discretization(bin_boundaries=PM_25_BOUNDARIES, output_mode='one_hot')\n",
        "\n",
        "@tf.function\n",
        "def merge_cols(x):\n",
        "    inputs = tf.convert_to_tensor(list(x.values()))\n",
        "    return tf.transpose(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b731f0b",
      "metadata": {
        "id": "4b731f0b",
        "outputId": "28319c27-5d9b-4eaa-ac90-a07392aba0ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<MapDataset element_spec=(TensorSpec(shape=(None, 16), dtype=tf.float32, name=None), TensorSpec(shape=(None, 4), dtype=tf.float32, name=None))>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ds = train_ds.map(lambda x, y: (\n",
        "    merge_cols(x), pm25_categories(y)))\n",
        "\n",
        "validation_ds = validation_ds.map(lambda x, y: (\n",
        "    merge_cols(x), pm25_categories(y)))\n",
        "\n",
        "test_ds = test_ds.map(lambda x, y: (\n",
        "    merge_cols(x), pm25_categories(y)))\n",
        "\n",
        "test_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c86c264f",
      "metadata": {
        "id": "c86c264f"
      },
      "source": [
        "# Extract x, y function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49580341",
      "metadata": {
        "id": "49580341"
      },
      "outputs": [],
      "source": [
        "def extract_features(dataset):\n",
        "    \"\"\"\n",
        "    Extracts features and target labels from a batched dataset and then converts them to NumPy arrays\n",
        "\n",
        "    Parameters:\n",
        "        dataset (tf.data.Dataset) - A batched dataset.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple (X, y) X being the features and y being the labels\n",
        "    \"\"\"\n",
        "    X_ds = dataset.map(lambda x, y: x)\n",
        "    y_ds = dataset.map(lambda x, y: y)\n",
        "    X = next(iter(X_ds))\n",
        "    y = next(iter(y_ds))\n",
        "    X = np.concatenate(list(X_ds.as_numpy_iterator()))    #this converts my data to a numpy X_train, y_train etc.. for rf\n",
        "    y = np.concatenate(list(y_ds.as_numpy_iterator()))\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3037de4",
      "metadata": {
        "id": "f3037de4"
      },
      "source": [
        "## Create time-based windows of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "249c1bea",
      "metadata": {
        "id": "249c1bea"
      },
      "outputs": [],
      "source": [
        "def windowify(dataset, window_size=SEQUENCE_LEN, batch_size=BATCH_SIZE):\n",
        "    fds = dataset.unbatch().window(window_size, shift=1)\n",
        "    fds_x = fds.flat_map(\n",
        "        lambda x, y: x.batch(window_size, drop_remainder=True))\n",
        "    fds_y = fds.flat_map(\n",
        "        lambda x, y: y.batch(window_size, drop_remainder=True))\n",
        "    fds_y = fds_y.map(lambda y: y[-1, :])\n",
        "    fds = tf.data.Dataset.zip((fds_x, fds_y))\n",
        "    fds = fds.shuffle(1000)\n",
        "    fds = fds.cache()\n",
        "    fds = fds.batch(batch_size)\n",
        "    return fds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cda5193b",
      "metadata": {
        "id": "cda5193b"
      },
      "source": [
        "# Windowfying regular and pca data below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "978c5da5",
      "metadata": {
        "id": "978c5da5",
        "outputId": "c466bdf3-aa9a-4fc3-907e-c33a9999f575"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(None, 5, 16), dtype=tf.float32, name=None), TensorSpec(shape=(None, 4), dtype=tf.float32, name=None))>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ds = windowify(train_ds)\n",
        "validation_ds = windowify(validation_ds)   # this is data that has no pca\n",
        "test_ds = windowify(test_ds)\n",
        "train_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "febbe2ac",
      "metadata": {
        "id": "febbe2ac"
      },
      "source": [
        "# Create X, y data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4cf94c3",
      "metadata": {
        "id": "f4cf94c3"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = extract_features(train_ds)\n",
        "X_test, y_test = extract_features(test_ds)\n",
        "X_valid, y_valid = extract_features(validation_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6fbae44",
      "metadata": {
        "id": "a6fbae44",
        "outputId": "82ea9438-171a-4747-faf8-a7abffa0815c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((222475, 5, 16), (222475, 4))"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c243ee13",
      "metadata": {
        "id": "c243ee13"
      },
      "source": [
        "# Create PCA data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3f3bcbb",
      "metadata": {
        "id": "e3f3bcbb"
      },
      "outputs": [],
      "source": [
        "X_train_flat = np.reshape(X_train, (-1, X_train.shape[-1]))\n",
        "X_valid_flat = np.reshape(X_valid, (-1, X_valid.shape[-1]))\n",
        "X_test_flat = np.reshape(X_test, (-1, X_test.shape[-1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83118348",
      "metadata": {
        "id": "83118348"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=16)\n",
        "pca.fit(X_train_flat)\n",
        "\n",
        "X_transformed = pca.transform(X_train_flat)\n",
        "X_valid_transformed = pca.transform(X_valid_flat)\n",
        "X_test_transformed = pca.transform(X_test_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "637171b2",
      "metadata": {
        "id": "637171b2"
      },
      "outputs": [],
      "source": [
        "explained_variance_ratio = pca.explained_variance_ratio_\n",
        "cumulative_explained_variance = np.cumsum(explained_variance_ratio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49568ceb",
      "metadata": {
        "id": "49568ceb",
        "outputId": "3f5c3f48-00a2-4fbf-d5e4-c689cb446cce"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(range(1, 17), pca.explained_variance_ratio_, 'bo-', linewidth=2)\n",
        "plt.xlabel('Number of components')\n",
        "plt.ylabel('Explained variance ratio')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "527952b2",
      "metadata": {
        "id": "527952b2"
      },
      "source": [
        "This graph is called a scree plot it helps determine a good number of components. at around 8-10 the graph levels out suggesting that a number from 8-10 would be a good choice to start with for my PCA n_components. So i started with 10 and gradually increased n_components 15 was what i decided to go with as the model was capturing most of the relevant data at this number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e05a17e0",
      "metadata": {
        "id": "e05a17e0",
        "outputId": "9b737c03-04f0-40bf-85fa-0bc524790d9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of components capturing 99.9% of the variance: 15\n"
          ]
        }
      ],
      "source": [
        "n_components = np.argmax(cumulative_explained_variance >= 0.999) + 1\n",
        "\n",
        "print(f\"Number of components capturing 99.9% of the variance: {n_components}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c073824",
      "metadata": {
        "id": "7c073824"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=15)\n",
        "pca.fit(X_train_flat)\n",
        "\n",
        "X_transformed = pca.transform(X_train_flat)\n",
        "X_valid_transformed = pca.transform(X_valid_flat)\n",
        "X_test_transformed = pca.transform(X_test_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0a47c10",
      "metadata": {
        "id": "a0a47c10"
      },
      "outputs": [],
      "source": [
        "X_transformed = np.reshape(X_transformed, (X_train.shape[0], X_train.shape[1], -1))\n",
        "X_valid_transformed = np.reshape(X_valid_transformed, (X_valid.shape[0], X_valid.shape[1], -1))\n",
        "X_test_transformed = np.reshape(X_test_transformed, (X_test.shape[0], X_test.shape[1], -1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea32b122",
      "metadata": {
        "id": "ea32b122",
        "outputId": "15d26afb-c777-4ae3-f897-52879a765c4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((222475, 5, 15), (65520, 5, 15), (94161, 5, 15))"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_transformed.shape, X_valid_transformed.shape, X_test_transformed.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42e5e0d0",
      "metadata": {
        "id": "42e5e0d0",
        "outputId": "5400b401-7bc2-4b36-9cf1-cadcd0e7ecb2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((222475, 5, 16), (65520, 5, 16), (94161, 5, 16))"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, X_valid.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "900c6ef5",
      "metadata": {
        "id": "900c6ef5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def my_generator():\n",
        "    for i in range(len(X_transformed)):\n",
        "        yield X_transformed[i], y_train[i]\n",
        "\n",
        "\n",
        "dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: my_generator(),\n",
        "    output_types=(tf.float32, tf.float32),\n",
        "    output_shapes=((SEQUENCE_LEN, X_transformed.shape[2]), (NUM_CLASSES,))  # was messing around with this correct function below\n",
        ")\n",
        "dataset = dataset.shuffle(buffer_size=1000)\n",
        "dataset = dataset.batch(batch_size)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2962fbb4",
      "metadata": {
        "id": "2962fbb4"
      },
      "outputs": [],
      "source": [
        "def create_dataset(X, y, shuffle=True, cache=True):\n",
        "    \"\"\"\n",
        "    Creates a TensorFlow dataset from the given input and target. As i couldn't get TF slices method of batching data\n",
        "    to work.\n",
        "\n",
        "    Args:\n",
        "        X (np.ndarray): Input array of windowed data with shape (num_samples, sequence_length, num_features).\n",
        "        y (np.ndarray): Target array with shape (num_samples, num_classes).\n",
        "        shuffle (bool, optional): Whether to shuffle the data. Defaults to True.\n",
        "        cache (bool, optional): Whether to cache the dataset in memory. Defaults to True.\n",
        "\n",
        "    Returns:\n",
        "        tf.data.Dataset: A TF dataset object containing the input and target data.\n",
        "    \"\"\"\n",
        "    def my_generator():\n",
        "        for i in range(len(X)):\n",
        "            yield X[i], y[i]\n",
        "\n",
        "    dataset = tf.data.Dataset.from_generator(\n",
        "        lambda: my_generator(),\n",
        "        output_types=(tf.float32, tf.float32),\n",
        "        output_shapes=((SEQUENCE_LEN, X.shape[2]), (NUM_CLASSES,))\n",
        "    )\n",
        "\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=1000)\n",
        "\n",
        "    if cache:\n",
        "        dataset = dataset.cache()\n",
        "\n",
        "    dataset = dataset.batch(batch_size)\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b7d1abb",
      "metadata": {
        "id": "0b7d1abb"
      },
      "outputs": [],
      "source": [
        "train_ds_pca = create_dataset(X_transformed, y_train)\n",
        "valid_ds_pca = create_dataset(X_valid_transformed, y_valid) #create batched datasets for pca data\n",
        "test_ds_pca = create_dataset(X_test_transformed, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f47e40c4",
      "metadata": {
        "id": "f47e40c4",
        "outputId": "244fe2d2-69d3-4bb3-a64d-8f903b3d7116"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(None, 5, 15), dtype=tf.float32, name=None), TensorSpec(shape=(None, 4), dtype=tf.float32, name=None))>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ds_pca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "268667c4",
      "metadata": {
        "id": "268667c4",
        "outputId": "b74072a6-7ee2-4074-8101-f5117ea73176"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(None, 5, 16), dtype=tf.float32, name=None), TensorSpec(shape=(None, 4), dtype=tf.float32, name=None))>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2701907b",
      "metadata": {
        "id": "2701907b"
      },
      "outputs": [],
      "source": [
        "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
        "X_valid = np.reshape(X_valid, (X_valid.shape[0], -1))  #reshape data so its suitable for RF\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], -1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a9b4c6a",
      "metadata": {
        "id": "4a9b4c6a",
        "outputId": "c2c16a9d-c6fc-4ceb-da97-680245f06a4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((222475, 80), (222475, 4))"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, y_train.shape #check shapes see if its compatable for rf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "607dcc78",
      "metadata": {
        "id": "607dcc78"
      },
      "source": [
        "# Quick data check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c50ca27",
      "metadata": {
        "id": "8c50ca27"
      },
      "outputs": [],
      "source": [
        "def calculate_class_counts(data, num_classes):\n",
        "    \"\"\"\n",
        "    Calculates number of samples for each class in dataset\n",
        "\n",
        "    Parameters:\n",
        "        data (tf.data.Dataset) - A batched dataset\n",
        "        num_classes (int): number of classes in the dataset.\n",
        "\n",
        "    Returns:\n",
        "        The function prints the number of samples for each class.\n",
        "    \"\"\"\n",
        "    class_counts = np.zeros(num_classes)\n",
        "    for x, y in data:\n",
        "        y = tf.argmax(y, axis=1)\n",
        "        class_counts += np.bincount(y, minlength=num_classes)\n",
        "    return print(f\"this data has this many classes: {class_counts}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2d01e4c",
      "metadata": {
        "id": "d2d01e4c",
        "outputId": "97767914-2330-4b5d-f992-f095e27c7f60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "this data has this many classes: [80159. 52977. 54089. 35250.]\n"
          ]
        }
      ],
      "source": [
        "calculate_class_counts(train_ds, NUM_CLASSES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49fabf37",
      "metadata": {
        "id": "49fabf37",
        "outputId": "9d60587d-395a-4c3c-a700-729c59fbab0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "this data has this many classes: [80159. 52977. 54089. 35250.]\n"
          ]
        }
      ],
      "source": [
        "calculate_class_counts(train_ds_pca, NUM_CLASSES)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d41fee16",
      "metadata": {
        "id": "d41fee16"
      },
      "source": [
        "# Base_model LSTM with no PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0f28112",
      "metadata": {
        "id": "f0f28112"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42) # set seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06aeb027",
      "metadata": {
        "id": "06aeb027"
      },
      "outputs": [],
      "source": [
        "lstm_base = Sequential([\n",
        "    LSTM(units=64, return_sequences=True, input_shape=(SEQUENCE_LEN, NUM_COLS)),\n",
        "    LSTM(units=32),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(NUM_CLASSES, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16f3ac81",
      "metadata": {
        "id": "16f3ac81",
        "outputId": "e23cfebe-b974-4f06-d0fa-4584334d6ac0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1739/1739 [==============================] - 14s 6ms/step - loss: 0.4703 - accuracy: 0.8019 - val_loss: 0.4381 - val_accuracy: 0.8161\n",
            "Epoch 2/10\n",
            "1739/1739 [==============================] - 9s 5ms/step - loss: 0.3993 - accuracy: 0.8333 - val_loss: 0.4184 - val_accuracy: 0.8262\n",
            "Epoch 3/10\n",
            "1739/1739 [==============================] - 10s 6ms/step - loss: 0.3843 - accuracy: 0.8397 - val_loss: 0.4075 - val_accuracy: 0.8308\n",
            "Epoch 4/10\n",
            "1739/1739 [==============================] - 9s 5ms/step - loss: 0.3735 - accuracy: 0.8451 - val_loss: 0.4036 - val_accuracy: 0.8327\n",
            "Epoch 5/10\n",
            "1739/1739 [==============================] - 9s 5ms/step - loss: 0.3645 - accuracy: 0.8490 - val_loss: 0.4018 - val_accuracy: 0.8339\n",
            "Epoch 6/10\n",
            "1739/1739 [==============================] - 9s 5ms/step - loss: 0.3563 - accuracy: 0.8527 - val_loss: 0.3979 - val_accuracy: 0.8349\n",
            "Epoch 7/10\n",
            "1739/1739 [==============================] - 10s 6ms/step - loss: 0.3487 - accuracy: 0.8559 - val_loss: 0.3975 - val_accuracy: 0.8352\n",
            "Epoch 8/10\n",
            "1739/1739 [==============================] - 9s 5ms/step - loss: 0.3413 - accuracy: 0.8594 - val_loss: 0.3963 - val_accuracy: 0.8358\n",
            "Epoch 9/10\n",
            "1739/1739 [==============================] - 9s 5ms/step - loss: 0.3341 - accuracy: 0.8622 - val_loss: 0.3964 - val_accuracy: 0.8368\n",
            "Epoch 10/10\n",
            "1739/1739 [==============================] - 10s 6ms/step - loss: 0.3275 - accuracy: 0.8646 - val_loss: 0.3959 - val_accuracy: 0.8370\n"
          ]
        }
      ],
      "source": [
        "lstm_base.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = lstm_base.fit(train_ds, validation_data=validation_ds, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fd9557b",
      "metadata": {
        "id": "7fd9557b"
      },
      "outputs": [],
      "source": [
        "# cache results\n",
        "lstm_base.save('lstm_base.h5')\n",
        "\n",
        "with open('lstm_base.json', 'w') as f:\n",
        "        json.dump(history.history, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cff36a04",
      "metadata": {
        "id": "cff36a04",
        "outputId": "7ad42169-f8d8-4b5c-d415-c58dfbdf22ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 5, 64)             20736     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 32)                12416     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 35,524\n",
            "Trainable params: 35,524\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "lstm_base.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a744b1b4",
      "metadata": {
        "id": "a744b1b4"
      },
      "source": [
        "# LSTM performance investigation 1: PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2d8edc7",
      "metadata": {
        "id": "b2d8edc7"
      },
      "outputs": [],
      "source": [
        "lstm_pca = Sequential([\n",
        "    LSTM(units=64, return_sequences=True, input_shape=(SEQUENCE_LEN, 15)),\n",
        "    LSTM(units=32),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(NUM_CLASSES, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b05d284c",
      "metadata": {
        "id": "b05d284c",
        "outputId": "7fb521a7-85fa-4404-de1c-2a692595f70c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1739/1739 [==============================] - 18s 9ms/step - loss: 0.4365 - accuracy: 0.8173 - val_loss: 0.4638 - val_accuracy: 0.8161\n",
            "Epoch 2/10\n",
            "1739/1739 [==============================] - 9s 5ms/step - loss: 0.3707 - accuracy: 0.8459 - val_loss: 0.4328 - val_accuracy: 0.8271\n",
            "Epoch 3/10\n",
            "1739/1739 [==============================] - 9s 5ms/step - loss: 0.3555 - accuracy: 0.8529 - val_loss: 0.4083 - val_accuracy: 0.8348\n",
            "Epoch 4/10\n",
            "1739/1739 [==============================] - 9s 5ms/step - loss: 0.3443 - accuracy: 0.8579 - val_loss: 0.3926 - val_accuracy: 0.8401\n",
            "Epoch 5/10\n",
            "1739/1739 [==============================] - 9s 5ms/step - loss: 0.3357 - accuracy: 0.8619 - val_loss: 0.3850 - val_accuracy: 0.8424\n",
            "Epoch 6/10\n",
            "1739/1739 [==============================] - 9s 5ms/step - loss: 0.3282 - accuracy: 0.8655 - val_loss: 0.3809 - val_accuracy: 0.8441\n",
            "Epoch 7/10\n",
            "1739/1739 [==============================] - 9s 5ms/step - loss: 0.3212 - accuracy: 0.8684 - val_loss: 0.3790 - val_accuracy: 0.8456\n",
            "Epoch 8/10\n",
            "1739/1739 [==============================] - 9s 5ms/step - loss: 0.3147 - accuracy: 0.8715 - val_loss: 0.3788 - val_accuracy: 0.8468\n",
            "Epoch 9/10\n",
            "1739/1739 [==============================] - 9s 5ms/step - loss: 0.3087 - accuracy: 0.8741 - val_loss: 0.3787 - val_accuracy: 0.8473\n",
            "Epoch 10/10\n",
            "1739/1739 [==============================] - 9s 5ms/step - loss: 0.3032 - accuracy: 0.8763 - val_loss: 0.3787 - val_accuracy: 0.8481\n"
          ]
        }
      ],
      "source": [
        "lstm_pca.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = lstm_pca.fit(train_ds_pca, validation_data=valid_ds_pca, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91720bfa",
      "metadata": {
        "id": "91720bfa"
      },
      "outputs": [],
      "source": [
        "# cache results\n",
        "lstm_pca.save('lstm_pca.h5')\n",
        "\n",
        "with open('lstm_pca.json', 'w') as f:\n",
        "        json.dump(history.history, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16bc869a",
      "metadata": {
        "id": "16bc869a",
        "outputId": "14c48e9a-e725-48ab-b679-02f806808019"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 5, 64)             20480     \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 32)                12416     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 35,268\n",
            "Trainable params: 35,268\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "lstm_pca.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3c7918a",
      "metadata": {
        "id": "b3c7918a"
      },
      "source": [
        "# LSTM  - performance investigation 2: Deeper model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2c75a3b",
      "metadata": {
        "id": "d2c75a3b"
      },
      "outputs": [],
      "source": [
        "lstm_deep = Sequential([\n",
        "    LSTM(units=64, return_sequences=True, input_shape=(SEQUENCE_LEN, NUM_COLS)),\n",
        "    Dropout(0.2),\n",
        "    LSTM(units=32),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(NUM_CLASSES, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6652500a",
      "metadata": {
        "id": "6652500a",
        "outputId": "6bdf7fb5-63bc-44e7-b6c7-f27516f98a31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1739/1739 [==============================] - 13s 6ms/step - loss: 0.5210 - accuracy: 0.7809 - val_loss: 0.4466 - val_accuracy: 0.8129\n",
            "Epoch 2/10\n",
            "1739/1739 [==============================] - 9s 5ms/step - loss: 0.4285 - accuracy: 0.8225 - val_loss: 0.4282 - val_accuracy: 0.8243\n",
            "Epoch 3/10\n",
            "1739/1739 [==============================] - 9s 5ms/step - loss: 0.4122 - accuracy: 0.8298 - val_loss: 0.4129 - val_accuracy: 0.8333\n",
            "Epoch 4/10\n",
            "1739/1739 [==============================] - 9s 5ms/step - loss: 0.4004 - accuracy: 0.8356 - val_loss: 0.4071 - val_accuracy: 0.8346\n",
            "Epoch 5/10\n",
            "1739/1739 [==============================] - 9s 5ms/step - loss: 0.3928 - accuracy: 0.8387 - val_loss: 0.4042 - val_accuracy: 0.8362\n",
            "Epoch 6/10\n",
            "1739/1739 [==============================] - 9s 5ms/step - loss: 0.3857 - accuracy: 0.8422 - val_loss: 0.4001 - val_accuracy: 0.8362\n",
            "Epoch 7/10\n",
            "1739/1739 [==============================] - 9s 5ms/step - loss: 0.3780 - accuracy: 0.8448 - val_loss: 0.4042 - val_accuracy: 0.8383\n",
            "Epoch 8/10\n",
            "1739/1739 [==============================] - 9s 5ms/step - loss: 0.3736 - accuracy: 0.8468 - val_loss: 0.3923 - val_accuracy: 0.8400\n",
            "Epoch 9/10\n",
            "1739/1739 [==============================] - 9s 5ms/step - loss: 0.3674 - accuracy: 0.8492 - val_loss: 0.3939 - val_accuracy: 0.8375\n",
            "Epoch 10/10\n",
            "1739/1739 [==============================] - 9s 5ms/step - loss: 0.3632 - accuracy: 0.8504 - val_loss: 0.3840 - val_accuracy: 0.8434\n"
          ]
        }
      ],
      "source": [
        "lstm_deep.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = lstm_deep.fit(train_ds, validation_data=validation_ds, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24229e56",
      "metadata": {
        "id": "24229e56"
      },
      "outputs": [],
      "source": [
        "# cache results\n",
        "lstm_deep.save('lstm_deep.h5')\n",
        "\n",
        "with open('lstm_deep.json', 'w') as f:\n",
        "        json.dump(history.history, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7828b8de",
      "metadata": {
        "id": "7828b8de",
        "outputId": "eded2158-8d94-4a4c-ce28-58dfe1644c5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_4 (LSTM)               (None, 5, 64)             20736     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 5, 64)             0         \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 32)                12416     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                2112      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               8320      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 4)                 516       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 44,100\n",
            "Trainable params: 44,100\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "lstm_deep.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "316d9e87",
      "metadata": {
        "id": "316d9e87"
      },
      "source": [
        "# Random Forest plain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc9edfc9",
      "metadata": {
        "id": "fc9edfc9",
        "outputId": "0087ee01-4566-4901-815e-c337632f7cbb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier()"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rfp = RandomForestClassifier(n_estimators=100)\n",
        "rfp.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "879d7f29",
      "metadata": {
        "id": "879d7f29",
        "outputId": "cd779809-aad9-4350-b6aa-b125e0d78553"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['rfp_model.joblib']"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "joblib.dump(rfp, 'rfp_model.joblib') # save model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b91b8c63",
      "metadata": {
        "id": "b91b8c63"
      },
      "source": [
        "# Random Forest - Performance investigation 3: changed hyper parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "230acfb2",
      "metadata": {
        "id": "230acfb2",
        "outputId": "8d039505-180b-48b7-edc3-6c835be1ef9e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=25, n_estimators=300)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=25, n_estimators=300)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(max_depth=25, n_estimators=300)"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rfh = RandomForestClassifier(n_estimators=300, max_depth=25) #n_estiamtors and max depth changed\n",
        "rfh.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "077e45a5",
      "metadata": {
        "id": "077e45a5",
        "outputId": "f1810361-7c4a-4796-afef-8d0b1fd44e82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['rfh_model.joblib']"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "joblib.dump(rfh, 'rfh_model.joblib') # save model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "346863df",
      "metadata": {
        "id": "346863df"
      },
      "source": [
        "# Final model on the test data PCA + DEEP + hyper param combined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61c70530",
      "metadata": {
        "id": "61c70530"
      },
      "outputs": [],
      "source": [
        "lstm_final = Sequential([\n",
        "    LSTM(units=64, return_sequences=True, input_shape=(SEQUENCE_LEN, 15)),\n",
        "    Dropout(0.2),\n",
        "    LSTM(units=32),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(NUM_CLASSES, activation='softmax')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "406f4087",
      "metadata": {
        "id": "406f4087",
        "outputId": "3d7e1c03-2471-4aa1-b030-9c2994a5233e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1739/1739 [==============================] - 22s 11ms/step - loss: 0.4924 - accuracy: 0.7927 - val_loss: 0.5245 - val_accuracy: 0.8016\n",
            "Epoch 2/20\n",
            "1739/1739 [==============================] - 10s 6ms/step - loss: 0.4103 - accuracy: 0.8306 - val_loss: 0.4748 - val_accuracy: 0.8172\n",
            "Epoch 3/20\n",
            "1739/1739 [==============================] - 10s 6ms/step - loss: 0.3939 - accuracy: 0.8381 - val_loss: 0.4421 - val_accuracy: 0.8254\n",
            "Epoch 4/20\n",
            "1739/1739 [==============================] - 10s 6ms/step - loss: 0.3843 - accuracy: 0.8423 - val_loss: 0.4409 - val_accuracy: 0.8289\n",
            "Epoch 5/20\n",
            "1739/1739 [==============================] - 10s 6ms/step - loss: 0.3748 - accuracy: 0.8469 - val_loss: 0.4307 - val_accuracy: 0.8327\n",
            "Epoch 6/20\n",
            "1739/1739 [==============================] - 10s 6ms/step - loss: 0.3673 - accuracy: 0.8495 - val_loss: 0.4236 - val_accuracy: 0.8358\n",
            "Epoch 7/20\n",
            "1739/1739 [==============================] - 10s 6ms/step - loss: 0.3614 - accuracy: 0.8526 - val_loss: 0.4192 - val_accuracy: 0.8377\n",
            "Epoch 8/20\n",
            "1739/1739 [==============================] - 10s 6ms/step - loss: 0.3573 - accuracy: 0.8539 - val_loss: 0.4263 - val_accuracy: 0.8362\n",
            "Epoch 9/20\n",
            "1739/1739 [==============================] - 10s 6ms/step - loss: 0.3513 - accuracy: 0.8569 - val_loss: 0.4260 - val_accuracy: 0.8378\n",
            "Epoch 10/20\n",
            "1739/1739 [==============================] - 10s 6ms/step - loss: 0.3492 - accuracy: 0.8574 - val_loss: 0.4209 - val_accuracy: 0.8391\n",
            "Epoch 11/20\n",
            "1739/1739 [==============================] - 10s 6ms/step - loss: 0.3455 - accuracy: 0.8591 - val_loss: 0.4164 - val_accuracy: 0.8407\n",
            "Epoch 12/20\n",
            "1739/1739 [==============================] - 10s 6ms/step - loss: 0.3416 - accuracy: 0.8609 - val_loss: 0.4161 - val_accuracy: 0.8396\n",
            "Epoch 13/20\n",
            "1739/1739 [==============================] - 10s 6ms/step - loss: 0.3372 - accuracy: 0.8622 - val_loss: 0.4193 - val_accuracy: 0.8416\n",
            "Epoch 14/20\n",
            "1739/1739 [==============================] - 10s 6ms/step - loss: 0.3345 - accuracy: 0.8641 - val_loss: 0.4059 - val_accuracy: 0.8423\n",
            "Epoch 15/20\n",
            "1739/1739 [==============================] - 10s 6ms/step - loss: 0.3326 - accuracy: 0.8648 - val_loss: 0.4062 - val_accuracy: 0.8444\n",
            "Epoch 16/20\n",
            "1739/1739 [==============================] - 10s 6ms/step - loss: 0.3291 - accuracy: 0.8661 - val_loss: 0.4148 - val_accuracy: 0.8437\n",
            "Epoch 17/20\n",
            "1739/1739 [==============================] - 10s 6ms/step - loss: 0.3263 - accuracy: 0.8671 - val_loss: 0.4043 - val_accuracy: 0.8460\n",
            "Epoch 18/20\n",
            "1739/1739 [==============================] - 10s 6ms/step - loss: 0.3238 - accuracy: 0.8683 - val_loss: 0.4080 - val_accuracy: 0.8460\n",
            "Epoch 19/20\n",
            "1739/1739 [==============================] - 10s 6ms/step - loss: 0.3214 - accuracy: 0.8702 - val_loss: 0.4030 - val_accuracy: 0.8459\n",
            "Epoch 20/20\n",
            "1739/1739 [==============================] - 10s 6ms/step - loss: 0.3192 - accuracy: 0.8703 - val_loss: 0.4051 - val_accuracy: 0.8467\n"
          ]
        }
      ],
      "source": [
        "lstm_final.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = lstm_final.fit(train_ds_pca, validation_data=test_ds_pca, epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "104609b0",
      "metadata": {
        "id": "104609b0"
      },
      "outputs": [],
      "source": [
        "lstm_final.save('lstm_final.h5')\n",
        "\n",
        "with open('lstm_final.json', 'w') as f:\n",
        "        json.dump(history.history, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec6ca95a",
      "metadata": {
        "id": "ec6ca95a",
        "outputId": "341a15d1-f96b-47b3-f563-f4c10f6c5963"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_8 (LSTM)               (None, 5, 64)             20480     \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 5, 64)             0         \n",
            "                                                                 \n",
            " lstm_9 (LSTM)               (None, 32)                12416     \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 64)                2112      \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 4)                 516       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43,844\n",
            "Trainable params: 43,844\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "lstm_final.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0afe365",
      "metadata": {
        "id": "f0afe365"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}